= Basic error handling

[quote, Werner Vogels]
Everything fails all the time.

Add `spring-retry` dependency together with `spring-boot-starter-aop`:

.pom.xml
[source,xml]
----
include::../pom.xml[tags=retry-deps]
----

You can either specify retry configuration directly via `@Retryable` properties or create `RetryInterceptor` bean and set it's name in `@Retryable` `interceptor` property.
For this demo we'll use simple configuration via `@Retryable`.

.MovieOperations.java
[source,java]
----
include::../src/main/java/com/example/demo/service/MovieOperations.java[]
----

<1> `@Retryable` specifies that the method(s) will be retied.
<2> `include` specifies exception types that should be retried.
<3> `maxAttempts` specifies number of max attempts of retries.
<4> `backoff` specifies backoff configuration for the retries.
<5> `random = true` enables jitter in backoff timeouts.

Add `@EnableRetry` either into existing `AerospikeConfiguration` or create separate class `AerospikeRetryConfiguration`:

.AerospikeRetryConfiguration.java
[source,java]
----
include::../src/main/java/com/example/demo/persistence/configuration/AerospikeRetryConfiguration.java[]
----

== Important points

=== Retryable and non retryable errors

In the context of retries there are two types of errors: retryable and non retryable. For example, retrieving value by key may result in `DataRetrievalFailureException` (key not found), which in most cases should not be retried; whereas in case there are connectivity issues to Aerospike or any network congestion issues you on the contrary would retry. Consider this when configuring your retry policy.

=== Backoff

When retrying errors there are two basic backoff policies: fixed and exponential. Fixed backoff policy does exactly how it's named, each retry occurs within fixed time interval. This backoff policy is simple and easy for understanding, but is not recommended for production, because in case external resource is overloaded and all clients experience issues, constantly increasing number of requests at the same time may lead to the total resource outage. Instead to overcome the issues resource should be given some time to heal, this can be achieved by exponential backoff policy, which increases each retry time interval by specific multiplier. This backoff polic usually is used together with jitter -- added randomized time interval into the backoff, which removes retry waves at specific time from multiple clients. With `spring-retry` you can use `org.springframework.retry.backoff.ExponentialRandomBackOffPolicy`.

=== Concurrent saves: `OptimisticLockingFailureException`

See link:docs_processed/concurrent-updates.adoc[Handling concurrent updates].

//TODO: how to simulate network latencies and test them